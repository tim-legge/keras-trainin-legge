{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ddcdcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 08:40:04.856312: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.path: ['/home/tim_legge/keras-trainin-legge', '/home/tim_legge/miniconda3/envs/tensorflow/lib/python37.zip', '/home/tim_legge/miniconda3/envs/tensorflow/lib/python3.7', '/home/tim_legge/miniconda3/envs/tensorflow/lib/python3.7/lib-dynload', '', '/home/tim_legge/miniconda3/envs/tensorflow/lib/python3.7/site-packages', '/home/tim_legge/miniconda3/envs/tensorflow/lib/python3.7/site-packages/IPython/extensions', '/home/tim_legge/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import numpy as np\n",
    "import os\n",
    "from train.train import parse_config, get_features\n",
    "from train.eval import makeRoc, plot_confusion_matrix\n",
    "from models.constraints import ZeroSomeWeights\n",
    "from layers.quantized_layers import Clip, BinaryDense, TernaryDense, QuantizedDense\n",
    "from models.models import binary_tanh, ternary_tanh, quantized_relu\n",
    "import yaml\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc42676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('j_ptfrac', 'j_pt', 'j_eta', 'j_mass', 'j_tau1_b1', 'j_tau2_b1', 'j_tau3_b1', 'j_tau1_b2', 'j_tau2_b2', 'j_tau3_b2', 'j_tau32_b1', 'j_tau32_b2', 'j_zlogz', 'j_c1_b0', 'j_c1_b1', 'j_c1_b2', 'j_c2_b1', 'j_c2_b2', 'j_d2_b1', 'j_d2_b2', 'j_d2_a1_b1', 'j_d2_a1_b2', 'j_m2_b1', 'j_m2_b2', 'j_n2_b1', 'j_n2_b2', 'j_tau1_b1_mmdt', 'j_tau2_b1_mmdt', 'j_tau3_b1_mmdt', 'j_tau1_b2_mmdt', 'j_tau2_b2_mmdt', 'j_tau3_b2_mmdt', 'j_tau32_b1_mmdt', 'j_tau32_b2_mmdt', 'j_c1_b0_mmdt', 'j_c1_b1_mmdt', 'j_c1_b2_mmdt', 'j_c2_b1_mmdt', 'j_c2_b2_mmdt', 'j_d2_b1_mmdt', 'j_d2_b2_mmdt', 'j_d2_a1_b1_mmdt', 'j_d2_a1_b2_mmdt', 'j_m2_b1_mmdt', 'j_m2_b2_mmdt', 'j_n2_b1_mmdt', 'j_n2_b2_mmdt', 'j_mass_trim', 'j_mass_mmdt', 'j_mass_prun', 'j_mass_sdb2', 'j_mass_sdm1', 'j_multiplicity', 'j1_px', 'j1_py', 'j1_pz', 'j1_e', 'j1_pdgid', 'j1_erel', 'j1_pt', 'j1_ptrel', 'j1_eta', 'j1_etarel', 'j1_etarot', 'j1_phi', 'j1_phirel', 'j1_phirot', 'j1_deltaR', 'j1_costheta', 'j1_costhetarel', 'j1_e1mcosthetarel', 'j_index', 'j_g', 'j_q', 'j_w', 'j_z', 'j_t', 'j_undef')\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('/mnt/c/ML_Data/processed-pythia82-lhc13-all-pt1-50k-r1_h022_e0175_t220_nonu_withPars_truth.z')\n",
    "treeArray = f['t_allpar_new'][()]\n",
    "print(treeArray.dtype.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "683a0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting features, similar to train.train\n",
    "\n",
    "with open(\"train/train_config_threelayer.yml\", \"r\") as file:\n",
    "    yamlConfig = yaml.safe_load(file)\n",
    "    \n",
    "    # List of features to use\n",
    "features = yamlConfig[\"Inputs\"]\n",
    "\n",
    "    # List of labels to use\n",
    "labels = yamlConfig[\"Labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f87932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Converts to dataframe\n",
    "features_labels_df = pd.DataFrame(treeArray, columns=list(set(features + labels)))\n",
    "features_labels_df = features_labels_df.drop_duplicates()\n",
    "\n",
    "features_df = features_labels_df[features]\n",
    "labels_df = features_labels_df[labels]\n",
    "    \n",
    "features_val = features_df.values\n",
    "labels_val = labels_df.values\n",
    "    \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        features_val, labels_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4646de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train_val)\n",
    "X_train_val = scaler.transform(X_train_val)\n",
    "X_test = scaler.transform(X_test)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc3966ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 32, 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 08:41:58.870269: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-23 08:41:58.874181: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "import models.models\n",
    "from keras.layers import Input\n",
    "print(yamlConfig['LayerSizes'])\n",
    "model = getattr(models.models, yamlConfig[\"KerasModel\"])\n",
    "keras_model = model(\n",
    "            Input(shape=X_train_val.shape[1:]),\n",
    "            y_train_val.shape[1],\n",
    "            l1Reg=yamlConfig[\"L1Reg\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d0e8169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.train import print_model_to_json\n",
    "outputDir = 'train_simple_l10p0001'\n",
    "print_model_to_json(keras_model, outputDir + \"/\" + \"KERAS_model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6f793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, Nadam\n",
    "startlearningrate = 0.0001\n",
    "adam = Adam(learning_rate=startlearningrate)\n",
    "keras_model.compile(optimizer=adam, loss=[yamlConfig[\"KerasLoss\"]], metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e677c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.callbacks import all_callbacks\n",
    "callbacks = all_callbacks(\n",
    "        stop_patience=1000,\n",
    "        lr_factor=0.5,\n",
    "        lr_patience=10,\n",
    "        lr_epsilon=0.000001,\n",
    "        lr_cooldown=2,\n",
    "        lr_minimum=0.0000001,\n",
    "        outputDir=outputDir,\n",
    "    )\n",
    "\n",
    "keras_model.fit(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    batch_size=1024,\n",
    "    epochs=100,\n",
    "    validation_split=0.25,\n",
    "    shuffle=True,\n",
    "    callbacks=callbacks.callbacks,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67d2909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputModel = 'train_simple_l10p0001/KERAS_check_best_model.h5'\n",
    "\n",
    "model = load_model(\n",
    "        inputModel,\n",
    "        custom_objects={\n",
    "            \"ZeroSomeWeights\": ZeroSomeWeights,\n",
    "            \"BinaryDense\": BinaryDense,\n",
    "            \"TernaryDense\": TernaryDense,\n",
    "            \"QuantizedDense\": QuantizedDense,\n",
    "            \"binary_tanh\": binary_tanh,\n",
    "            \"ternary_tanh\": ternary_tanh,\n",
    "            \"quantized_relu\": quantized_relu,\n",
    "            \"Clip\": Clip,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb119cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in makeRoc()\n",
      "617/617 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'train_simple_l10p0001'\n",
    "y_predict = makeRoc(X_test, labels, y_test, model, outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdcf2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = y_test.argmax(axis=1)\n",
    "y_predict_proba = y_predict.argmax(axis=1)\n",
    "# Compute non-normalized confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test_proba, y_predict_proba)\n",
    "np.set_printoptions(precision=2)\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(\n",
    "    cnf_matrix,\n",
    "    classes=[l.replace(\"j_\", \"\") for l in labels],\n",
    "    title=\"Confusion matrix\",\n",
    "    )\n",
    "plt.figtext(\n",
    "    0.28,\n",
    "    0.90,\n",
    "    \"hls4ml\",\n",
    "    fontweight=\"bold\",\n",
    "    wrap=True,\n",
    "    horizontalalignment=\"right\",\n",
    "    fontsize=14,\n",
    "    )\n",
    "    # plt.figtext(0.38, 0.90,'preliminary', style='italic', wrap=True, horizontalalignment='center', fontsize=14)\n",
    "plt.savefig(outputDir + \"/confusion_matrix.pdf\")\n",
    "    # Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(\n",
    "    cnf_matrix,\n",
    "    classes=[l.replace(\"j_\", \"\") for l in labels],\n",
    "    normalize=True,\n",
    "    title=\"Normalized confusion matrix\",\n",
    "    )\n",
    "\n",
    "plt.figtext(\n",
    "    0.28,\n",
    "    0.90,\n",
    "    \"hls4ml\",\n",
    "    fontweight=\"bold\",\n",
    "    wrap=True,\n",
    "    horizontalalignment=\"right\",\n",
    "    fontsize=14,\n",
    "    )\n",
    "    # plt.figtext(0.38, 0.90,'preliminary', style='italic', wrap=True, horizontalalignment='center', fontsize=14)\n",
    "plt.savefig(outputDir + \"/confusion_matrix_norm.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80313d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
